<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Operations on Monasca</title>
    <link>http://monasca.io/categories/operations/</link>
    <description>Recent content in Operations on Monasca</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Â© 2015 Hewlett Packard Enterprise</copyright>
    <lastBuildDate>Tue, 18 Aug 2015 17:09:52 -0600</lastBuildDate>
    <atom:link href="http://monasca.io/categories/operations/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>deployment</title>
      <link>http://monasca.io/operations/deployment/</link>
      <pubDate>Tue, 18 Aug 2015 17:09:52 -0600</pubDate>
      
      <guid>http://monasca.io/operations/deployment/</guid>
      <description>&lt;p&gt;Monasca is a system built for large scale deployments. One side effect of this is there are many components in the system each of which is an
installation in and of itself. The end result of this is that I highly recommend you use a configuration management system to install Monasca.&lt;/p&gt;

&lt;p&gt;The HP Monasca team has published a set of &lt;a href=&#34;http://www.ansible.com/home&#34;&gt;Ansible&lt;/a&gt; roles that can be used to install and configure Monasca on
Debian/Ubuntu based machines. These roles all are in repos that start with &amp;lsquo;ansible-&amp;rsquo; and are available on github under the
&lt;a href=&#34;https://github.com/hpcloud-mon?utf8=%E2%9C%93&amp;amp;query=ansible-&#34;&gt;hpcloud-mon organization&lt;/a&gt;. These roles are used in the &lt;a href=&#34;http://monasca.io/dev/vagrant/&#34;&gt;Monasca Vagrant&lt;/a&gt;
development environment but are also used internally at HP for full HA installations of Monasca.&lt;/p&gt;

&lt;p&gt;In addition to the Ansible roles a &lt;a href=&#34;https://puppetlabs.com/&#34;&gt;Puppet&lt;/a&gt; module is maintained by the Monasca community in the
&lt;a href=&#34;https://github.com/openstack/puppet-monasca&#34;&gt;puppet-monasca&lt;/a&gt; git repository.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Monitoring of Monitoring</title>
      <link>http://monasca.io/operations/mom/</link>
      <pubDate>Fri, 14 Aug 2015 16:42:17 -0600</pubDate>
      
      <guid>http://monasca.io/operations/mom/</guid>
      <description>&lt;p&gt;Monasca itself needs to be monitored and is fully capable of monitoring itself.  In non-production installations this can be done by the agent running on the Monasca boxes reporting back to the Monasca API. For production installations I recommend that the agent running on the Monasca nodes report to another installation of Monasca possibly a single vm &amp;lsquo;mini-mon&amp;rsquo; which is itself monitored by the primary installation, this avoids dependency loops.&lt;/p&gt;

&lt;p&gt;As components of Monasca are developed metrics for the monitoring of that component need to be added as well as alarm definitions and finally default graphs to view the metrics. The most basic metrics are used in simple up/down alarms and more advanced used for thresholds and graphs aiding in predictive failure and capacity planning.&lt;/p&gt;

&lt;p&gt;Here are the MoM alarms broken down by component, the exact alarms can be found at &lt;a href=&#34;https://github.com/hpcloud-mon/ansible-monasca-default-alarms/blob/master/tasks/monasca.yml&#34;&gt;https://github.com/hpcloud-mon/ansible-monasca-default-alarms/blob/master/tasks/monasca.yml&lt;/a&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Component&lt;/th&gt;
&lt;th&gt;Alarm&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;zookeeper&lt;/td&gt;
&lt;td&gt;pid check, average latency, zookeeper connections_count&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;kafka&lt;/td&gt;
&lt;td&gt;pid check, consumer lag&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;mysql&lt;/td&gt;
&lt;td&gt;pid check, slow queries&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;notification&lt;/td&gt;
&lt;td&gt;pid check, config db time, email time&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;thresh/storm&lt;/td&gt;
&lt;td&gt;pid check of nimbus, supervisor and workers&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Agent&lt;/td&gt;
&lt;td&gt;emit time, collection time&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Persister&lt;/td&gt;
&lt;td&gt;For the Java version a healthcheck on the admin url&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;API&lt;/td&gt;
&lt;td&gt;For the Java version a healthcheck on the admin url&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
  </channel>
</rss>